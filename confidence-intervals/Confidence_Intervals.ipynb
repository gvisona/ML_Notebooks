{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ee7ad16-a967-438a-b63b-668d7bcc2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b73cf2-73cc-4507-b010-53ae1b24a69f",
   "metadata": {},
   "source": [
    "# The setup\n",
    "\n",
    "Imagine you have a research question, a dataset, and a novel model that you are sure will do better. \n",
    "How do you robustly compare it to any baseline you have, so to have convincing results to present?\n",
    "\n",
    "Let us create some mock data to represent the problem, and analyze the use of statistical tests and confidence intervals within this context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257299db-07f2-4e38-bc2a-610779ee61aa",
   "metadata": {},
   "source": [
    "## Simulating an experiment\n",
    "\n",
    "We have a dataset, two baselines (B1 and B2), and our proposed model (M).\n",
    "\n",
    "We split the dataset into training and test set, train the model, and measure the Mean Squared Error (MSE).\n",
    "The measure of the performance of a model is a random variable, and we will skip here any form of training and simply sample\n",
    "from some underlying distribution to have some results to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb07299-0e8f-4272-99dd-7c183bb8f1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>0.880431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>0.845299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0.854769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       MSE\n",
       "0    B1  0.880431\n",
       "1    B2  0.845299\n",
       "2     M  0.854769"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "results = []\n",
    "results.append({\"Model\": \"B1\", \"MSE\": np.random.normal(loc=0.87, scale=0.021)})\n",
    "results.append({\"Model\": \"B2\", \"MSE\": np.random.normal(loc=0.85, scale=0.034)})\n",
    "results.append({\"Model\": \"M\", \"MSE\": np.random.normal(loc=0.79, scale=0.10)})\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d602c5-44fe-4e33-bcec-2609cc3a3a68",
   "metadata": {},
   "source": [
    "Notice that if we repeat the procedure, we will get different results, that might even flip any ranking that we derive. \n",
    "This is not just an artifact of this notebook, but a real fact of research projects: if you repeat the same experiment with a different\n",
    "train/test split, or with a different initialization of parameters, or possibly even just a different seed, you will get a different metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f174d95-42f9-44e8-8cbb-c0c8e8661a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>0.901984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>0.842039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0.766586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       MSE\n",
       "0    B1  0.901984\n",
       "1    B2  0.842039\n",
       "2     M  0.766586"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "results.append({\"Model\": \"B1\", \"MSE\": np.random.normal(loc=0.87, scale=0.021)})\n",
    "results.append({\"Model\": \"B2\", \"MSE\": np.random.normal(loc=0.85, scale=0.034)})\n",
    "results.append({\"Model\": \"M\", \"MSE\": np.random.normal(loc=0.79, scale=0.10)})\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa0b82-d057-40dc-b56d-e89d950341da",
   "metadata": {},
   "source": [
    "## Repeated evaluations\n",
    "\n",
    "To solve this issue, we need to have multiple measurements of a model's performance, so that we may draw conclusions about their distribution.\n",
    "One way to achieve that is with a method like [nested cross-validation](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/), or by sampling multiple train/test splits. Using multiple training runs with the same train/test split is not recommended, as it is overly biased to this specific data split.\n",
    "\n",
    "Let us assume that we have performed 5-fold nested cross-validation, with the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4de216-2edd-4dfc-8dfa-c3655c967056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Split</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.858192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.815564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>0.821425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.850931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.801982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>0.936565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Split       MSE\n",
       "0     B1      0  0.903163\n",
       "1     B2      0  0.876093\n",
       "2      M      0  0.743053\n",
       "3     B1      1  0.881394\n",
       "4     B2      1  0.834244\n",
       "5      M      1  0.743427\n",
       "6     B1      2  0.875081\n",
       "7     B2      2  0.784948\n",
       "8      M      2  0.617508\n",
       "9     B1      3  0.858192\n",
       "10    B2      3  0.815564\n",
       "11     M      3  0.821425\n",
       "12    B1      4  0.850931\n",
       "13    B2      4  0.801982\n",
       "14     M      4  0.936565"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for split_idx in range(5):\n",
    "    results.append({\"Model\": \"B1\", \"Split\": split_idx, \"MSE\": np.random.normal(loc=0.87, scale=0.021)})\n",
    "    results.append({\"Model\": \"B2\", \"Split\": split_idx, \"MSE\": np.random.normal(loc=0.85, scale=0.034)})\n",
    "    results.append({\"Model\": \"M\", \"Split\": split_idx, \"MSE\": np.random.normal(loc=0.79, scale=0.10)})\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be320e-424f-471d-a967-a0e45a60fa9d",
   "metadata": {},
   "source": [
    "We can now summarize the performance of each model by averaging over the different splits. \n",
    "Thanks to the magic of the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem), this method will provide a more representative estimate of the \n",
    "performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8373e6-63b1-4a9d-a394-94e4c01e70ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.873752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.822566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.772395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE\n",
       "Model          \n",
       "B1     0.873752\n",
       "B2     0.822566\n",
       "M      0.772395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = results.drop(\"Split\", axis=1).groupby(\"Model\").mean()\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51ff37-31bd-4356-b07d-b6701ed4987a",
   "metadata": {},
   "source": [
    "But how confident are we in these results? We could provide a measure of uncertainty using the [Standard Error of the Mean](https://en.wikipedia.org/wiki/Standard_error).\n",
    "This approach is correct, but not quite interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aaeb50d-e1a7-411d-ab72-9e71005c04cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE_stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.009187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.015635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.052462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MSE_stderr\n",
       "Model            \n",
       "B1       0.009187\n",
       "B2       0.015635\n",
       "M        0.052462"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_err_df = results.drop(\"Split\", axis=1).groupby(\"Model\").std()/np.sqrt(5)\n",
    "std_err_df.columns = [\"MSE_stderr\"]\n",
    "std_err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd70a13f-e7d7-4b37-8244-b4be23a4c4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE_stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.873752</td>\n",
       "      <td>0.009187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.822566</td>\n",
       "      <td>0.015635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.772395</td>\n",
       "      <td>0.052462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE  MSE_stderr\n",
       "Model                      \n",
       "B1     0.873752    0.009187\n",
       "B2     0.822566    0.015635\n",
       "M      0.772395    0.052462"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = mean_df.join(std_err_df)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1613a3-5e1f-49fd-acda-e2b03ab1d1f5",
   "metadata": {},
   "source": [
    "## Calculating the confidence intervals\n",
    "\n",
    "A much better alternative is the use of [Confidence Intervals](https://en.wikipedia.org/wiki/Confidence_interval), ranges of values that\n",
    "contain the target metric (average performance), with a specified level of confidence. \n",
    "\n",
    "The process to obtain confidence intervals is the following:\n",
    "- Specify what level of confidence you want to have (95% is a pretty common choice, meaning that with 95% probability the true value will be inside the interval).\n",
    "- Identify the distribution of the target quantity\n",
    "- Find the quantiles that reflect your desired confidence intervals\n",
    "\n",
    "Let us see how this works in our example:\n",
    "\n",
    "- We choose 95% as the standard CI level of confidence. \n",
    "- Our target metric is the average MSE. Being an average of a sample of 5 measurements, this quantity follows a [t-Distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) with 4 Degrees of Freedom, mean $\\mu$ (the expected value of the mean), and standard deviation equal to the standard error of the mean $\\frac{\\sigma}{\\sqrt{n}}$, where $\\sigma$ is the population standard deviation of the measurements.\n",
    "- Using Maximum likelihood, we can substitute the observed values as estimates of the distribution parameters\n",
    "- Given the way the standard t-Distribution can be transformed and scaled (analogous to the Gaussian distribution), we can calculate the necessary quantiles using the standard t-Distribution with the correct number of DoFs, and then shift and scale the results with the estimated values.\n",
    "- So if $\\bar{X}$ is the average MSE for a model, and $S$ is the standard deviation obtained from the $n=5$ measurements, the confidence interval that we are looking for is $\\bar{X} \\pm t_q * \\frac{S}{\\sqrt{n}}$. In this formula, $t_q$ is the selected quantile calculated using the standard t-Distribution, and we can use teh $\\pm$ notation because the distribution is symmetrical with respect to the mean.\n",
    "- Since we want to have 95% confidence intervals centered around the mean, we will use the quantiles (2.5%, 97.5%), which are symmetrical.\n",
    "\n",
    "Using this setup, we obtain the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba52135-f959-4087-adae-d872b4601774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.1923843459783338)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dof=4\n",
    "t_q = scipy.stats.t.sf(0.975, dof)\n",
    "t_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c55b090-6e03-4ff0-a574-a86cddb8560d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE_stderr</th>\n",
       "      <th>Half_CI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.873752</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.822566</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>0.003008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.772395</td>\n",
       "      <td>0.052462</td>\n",
       "      <td>0.010093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE  MSE_stderr   Half_CI\n",
       "Model                                \n",
       "B1     0.873752    0.009187  0.001767\n",
       "B2     0.822566    0.015635  0.003008\n",
       "M      0.772395    0.052462  0.010093"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df[\"Half_CI\"] = summary_df[\"MSE_stderr\"]*t_q\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57e2d964-66c3-446b-9501-5701e607211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model B1: 0.874 ± 0.002\n",
      "Model B2: 0.823 ± 0.003\n",
      "Model M: 0.772 ± 0.010\n"
     ]
    }
   ],
   "source": [
    "for i, row in summary_df.iterrows():\n",
    "    print(f\"Model {i}: {row.MSE:.3f} ± {row.Half_CI:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329689b-d069-4328-b139-7c807ab60dc0",
   "metadata": {},
   "source": [
    "## What if my confidence intervals overlap?\n",
    "\n",
    "CIs are a good representation of the performance, but you might want to convey a firm yes or no answer to the question \"Is my model clearly better than the rest?\".\n",
    "To provide such an outcome, we can make use of suitable statistical tests, such as the [t-test](https://en.wikipedia.org/wiki/Student%27s_t-test).\n",
    "The procedure goes as follows:\n",
    "- Select a statistical significance threshold (0.05 is common, although I personally prefer to use 0.01).\n",
    "- Take the model with the best average metric, and perform a pairwise t-test between it and each of the other models. If any of those tests fails to reject the null hypothesis at the chosen significance threshold, we cannot confidently claim that the performance difference of the two models is statistically significant, and they should be reported as comparable.\n",
    "\n",
    "Since the variance of the samples for each model is not necessarily equal, we can make use of the [Welch's t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test) rather than a simple t-test.\n",
    "\n",
    "It is a matter of debate whether you should use some multiple hypothesis correction (such as the Bonferroni correction, or the Benjamini-Hochberg procedure) to this set of comparisons. If you want to err on the side of caution, you should include this step. \n",
    "\n",
    "With our results, the process is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00d3ab6c-28a6-4351-b68e-d5cb6fd9a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between model M and model B1 is NOT statistically significant: pvalue 0.12565754369221083\n",
      "The difference between model M and model B2 is NOT statistically significant: pvalue 0.40394414226204217\n"
     ]
    }
   ],
   "source": [
    "statistical_significance_threshold = 0.01\n",
    "best_model_samples = results[results[\"Model\"]==\"M\"][\"MSE\"].tolist()\n",
    "\n",
    "for alternative_model in [\"B1\", \"B2\"]:\n",
    "    alternative_model_samples = results[results[\"Model\"]==alternative_model][\"MSE\"].tolist()\n",
    "    ttest_result = scipy.stats.ttest_ind(best_model_samples, alternative_model_samples, equal_var=False)\n",
    "    if ttest_result.pvalue<statistical_significance_threshold:\n",
    "        print(f\"Difference between model M and model {alternative_model} is statistically significant: pvalue {ttest_result.pvalue}\")\n",
    "    else:\n",
    "        print(f\"The difference between model M and model {alternative_model} is NOT statistically significant: pvalue {ttest_result.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56276d11-1fe1-44cd-a960-ecb15abb3762",
   "metadata": {},
   "source": [
    "We see that in this case the difference is not statistically significant when comparing to either baseline.\n",
    "But how can that be? We can clearly see in the mock data creation that we used different distributions.\n",
    "The answer is lack of [statistical power](https://en.wikipedia.org/wiki/Power_(statistics)), due to the fact that we only used 5 samples per model. \n",
    "We can see the difference if we repead the same procedure with 100 samples per model. (In a real work you should NOT adjust the number of samples based on the results without repeating your experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89b0a09b-f38c-42f7-999d-9bca1dc98181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between model M and model B1 is statistically significant: pvalue 6.9385199674497656e-09\n",
      "Difference between model M and model B2 is statistically significant: pvalue 0.00022120169695229422\n"
     ]
    }
   ],
   "source": [
    "results_many_samples = []\n",
    "for split_idx in range(100):\n",
    "    results_many_samples.append({\"Model\": \"B1\", \"Split\": split_idx, \"MSE\": np.random.normal(loc=0.87, scale=0.021)})\n",
    "    results_many_samples.append({\"Model\": \"B2\", \"Split\": split_idx, \"MSE\": np.random.normal(loc=0.85, scale=0.034)})\n",
    "    results_many_samples.append({\"Model\": \"M\", \"Split\": split_idx, \"MSE\": np.random.normal(loc=0.79, scale=0.10)})\n",
    "results_many_samples = pd.DataFrame(results_many_samples)\n",
    "\n",
    "\n",
    "best_model_samples = results_many_samples[results_many_samples[\"Model\"]==\"M\"][\"MSE\"].tolist()\n",
    "\n",
    "for alternative_model in [\"B1\", \"B2\"]:\n",
    "    alternative_model_samples = results_many_samples[results_many_samples[\"Model\"]==alternative_model][\"MSE\"].tolist()\n",
    "    ttest_result = scipy.stats.ttest_ind(best_model_samples, alternative_model_samples, equal_var=False)\n",
    "    if ttest_result.pvalue<statistical_significance_threshold:\n",
    "        print(f\"Difference between model M and model {alternative_model} is statistically significant: pvalue {ttest_result.pvalue}\")\n",
    "    else:\n",
    "        print(f\"The difference between model M and model {alternative_model} is NOT statistically significant: pvalue {ttest_result.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd006e-89ce-421f-afbd-5f8f67359f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
